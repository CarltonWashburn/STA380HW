Boston[419,'indus']
plot(Boston$chas,Boston$crim)
plot(Boston$nox,Boston$crim)
plot(Boston$rm,Boston$crim)
plot(Boston$age,Boston$crim)
plot(Boston$dis,Boston$crim)
plot(Boston$rad,Boston$crim)
plot(Boston$tax,Boston$crim)
plot(Boston$ptratio,Boston$crim)
identify(Boston$ptratio,Boston$crim)
Boston[381,'ptratio']
plot(Boston$black,Boston$crim)
plot(Boston$lstat,Boston$crim)
plot(Boston$medv,Boston$crim)
summary(Boston$crim)
sd(Boston$crim)
summary(Boston$tax)
hist(Boston$tax)
sd(Boston$tax)
summary(Boston$ptratio)
hist(Boston$ptratio)
sd(Boston$ptratio)
charles = Boston[which(Boston$chas == 1)]
charles = Boston[,which(Boston$chas == 1)]
charles = Boston[which(Boston$chas == 1),]
summary(Boston$medv)
lowest = Boston[which(Boston$medv == 5),]
lowest
summary(Boston$black)
seven = Boston[which(Boston$rm > 7),]
dim(seven)
eight = Boston[which(Boston$rm > 8),]
dim(eight)
summary(eight)
rm(list=ls())
attach(Boston)
lm.zn = lm(crim~zn)
lm.indus = lm(crim~indus)
lm.chas = lm(crim~chas)
lm.nox = lm(crim~nox)
lm.rm = lm(crim~rm)
lm.age = lm(crim~age)
lm.dis - lm(crim~dis)
lm.dis = lm(crim~dis)
lm.rad = lm(crim~rad)
lm.tax = lm(crim~tax)
lm.ptratio = lm(crim~ptratio)
lm.black = lm(crim~black)
lm.lstat = lm(crim~lstat)
lm.medv = lm(crim~medv)
summary(lm.age)
summary(lm.zn)
plot(zn,crim)
abline(lm.zn)
summary(lm.indus)
summary(lm.chas)
summary(lm.nox)
summary(lm.rm)
summary(lm.age)
summary(lm.dis)
summary(lm.rad)
summary(lm.tax)
summary(lm.ptratio)
summary(lm.black)
summary(lm.lstat)
summary(lm.medv)
plot(zn,crim)
plot(indus,crim)
plot(nox,crim)
plot(rm,crim)
abline(lm.nox)
abline(lm.rm)
plot(dis,crim)
abline(lm.dis)
abline(lm.dis,col=red)
abline(lm.dis,col=2)
abline(lm.dis,col=2,lwd=3)
plot(rad,crim)
plot(tax,crim
crim
plot(tax,crim)
plot(ptratio,crim)
plot(black,crim)
abline(lm.black)
abline(lm.black,col=2,lwd=3)
plot(medv,crim)
abline(lm.medv,col=2,lwd=3)
plot(lstat,crim)
abline(lm.lstat,col=3,lwd=3)
lm.multi = lm(crim~.)
lm.multi = lm(crim~.,data=Boston)
summary(lm.multi)
coef(lm.age)
coef(lm.age)[2]
coef(lm.multi)[2]
coef(lm.multi)[3]
coef(lm.multi)
coefs = []
coefs = [,]
coefs = [13,2]
coefs[1,1]
coefs[1,1] = coef(lm.zn)[2]
coefs = matrix(nrow = 13, ncol = 2)
coefs[1,1]
coefs[1,2]
coefs[1,1] = coef(lm.zn)[2]
coefs[2,1] = coef(lm.indus)[2]
coefs[3,1] = coef(lm.chas)[2]
coefs[4,1] = coef(lm.nox)[2]
coefs[5,1] = coef(lm.rm)[2]
coefs[6,1] = coef(lm.age)[2]
coefs[7,1] = coef(lm.dis)[2]
coefs[8,1] = coef(lm.rad)[2]
coefs[9,1] = coef(lm.tax)[2]
coefs[10,1] = coef(lm.ptratio)[2]
coefs[11,1] = coef(lm.black)[2]
coefs[12,1] = coef(lm.lstat)[2]
coefs[13,1] = coef(lm.medv)[2]
for (i in seq(1:13))
coefs[i,2] = coef(lm.multi)[i+1]
plot(coefs[,1],coefs[,2])
summary(lm.multi)
nonlin=function(value,predictor){
lm.data = lm(value~poly(predictor,3))
return(lm.data)
}
nlm.zn = nonlin(crim,zn)
nlm.indus = nonlin(crim,indus)
nlm.chas = nonlin(crim,chas)
nlm.nox = nonlin(crim,nox)
nlm.rm = nonlin(crim,rm)
nlm.age = nonlin(crim,age)
nlm.dis = nonlin(crim,dis)
nlm.rad = nonlin(crim,rad)
nlm.tax = nonl;in(crim,tax)
nlm.tax = nonlin(crim,tax)
nlm.ptratio = nonlin(crim,ptratio)
nlm.black = nonlin(crim,black)
nlm.lstat = nonlin(crim,lstat)
nlm.medv = nonlin(crim,medv)
library(tm)
author_dirs = Sys.glob('../data/ReutersC50/C50train/*')
author_dirs = author_dirs[1:2]
file_list = NULL
labels = NULL
for(author in author_dirs) {
author_name = substring(author, first=29)
files_to_add = Sys.glob(paste0(author, '/*.txt'))
file_list = append(file_list, files_to_add)
labels = append(labels, rep(author_name, length(files_to_add)))
}
# Need a more clever regex to get better names here
all_docs = lapply(file_list, readerPlain)
names(all_docs) = file_list
names(all_docs) = sub('.txt', '', names(all_docs))
readerPlain = function(fname){
readPlain(elem=list(content=readLines(fname)),
id=fname, language='en') }
author_dirs = Sys.glob('../data/ReutersC50/C50train/*')
author_dirs = author_dirs[1:2]
file_list = NULL
labels = NULL
for(author in author_dirs) {
author_name = substring(author, first=29)
files_to_add = Sys.glob(paste0(author, '/*.txt'))
file_list = append(file_list, files_to_add)
labels = append(labels, rep(author_name, length(files_to_add)))
}
# Need a more clever regex to get better names here
all_docs = lapply(file_list, readerPlain)
names(all_docs) = file_list
names(all_docs) = sub('.txt', '', names(all_docs))
my_corpus = Corpus(VectorSource(all_docs))
names(my_corpus) = file_list
# Preprocessing
my_corpus = tm_map(my_corpus, content_transformer(tolower)) # make everything lowercase
my_corpus = tm_map(my_corpus, content_transformer(removeNumbers)) # remove numbers
my_corpus = tm_map(my_corpus, content_transformer(removePunctuation)) # remove punctuation
my_corpus = tm_map(my_corpus, content_transformer(stripWhitespace)) ## remove excess white-space
my_corpus = tm_map(my_corpus, content_transformer(removeWords), stopwords("SMART"))
DTM = DocumentTermMatrix(my_corpus)
DTM # some basic summary statistics
class(DTM)  # a special kind of sparse matrix format
setwd("~/Google Drive/UT/Business Analytics/Summer 2015/Predictive Modeling/Scott/STA380/R")
library(tm)
# Remember to source in the "reader" wrapper function
## Rolling two directories together into a single corpus
author_dirs = Sys.glob('../data/ReutersC50/C50train/*')
author_dirs = author_dirs[1:2]
file_list = NULL
labels = NULL
for(author in author_dirs) {
author_name = substring(author, first=29)
files_to_add = Sys.glob(paste0(author, '/*.txt'))
file_list = append(file_list, files_to_add)
labels = append(labels, rep(author_name, length(files_to_add)))
}
# Need a more clever regex to get better names here
all_docs = lapply(file_list, readerPlain)
names(all_docs) = file_list
names(all_docs) = sub('.txt', '', names(all_docs))
my_corpus = Corpus(VectorSource(all_docs))
names(my_corpus) = file_list
# Preprocessing
my_corpus = tm_map(my_corpus, content_transformer(tolower)) # make everything lowercase
my_corpus = tm_map(my_corpus, content_transformer(removeNumbers)) # remove numbers
my_corpus = tm_map(my_corpus, content_transformer(removePunctuation)) # remove punctuation
my_corpus = tm_map(my_corpus, content_transformer(stripWhitespace)) ## remove excess white-space
my_corpus = tm_map(my_corpus, content_transformer(removeWords), stopwords("SMART"))
DTM = DocumentTermMatrix(my_corpus)
DTM # some basic summary statistics
class(DTM)  # a special kind of sparse matrix format
inspect(DTM[1:10,1:20])
DTM = removeSparseTerms(DTM, 0.975)
DTM
# Now a dense matrix
X = as.matrix(DTM)
AP_train = X[1:45,]
AP_train
AC_train = X[51:95,]
AC_train
setwd("~/Google Drive/UT/Business Analytics/Summer 2015/Predictive Modeling/Scott/HW Repository/STA380HW/HW2")
setwd("~/Google Drive/UT/Business Analytics/Summer 2015/Predictive Modeling/Scott/HW Repository/STA380HW/HW2")
setwd("~/Google Drive/UT/Business Analytics/Summer 2015/Predictive Modeling/Scott/HW Repository/STA380HW/HW2")
author_dirs = c(author_train,author_test)
author_train = Sys.glob('./ReutersC50/C50train/*')
author_test = Sys.glob('./ReutersC50/C50test/*')
author_dirs = c(author_train,author_test)
#author_dirs = author_dirs[1:2]
file_list = NULL
labels = NULL
for(author in author_dirs) {
author_name = substring(author, first=23)
files_to_add = Sys.glob(paste0(author, '/*.txt'))
file_list = append(file_list, files_to_add)
labels = append(labels, rep(author_name, length(files_to_add)))
}
# Need a more clever regex to get better names here
all_docs = lapply(file_list, readerPlain)
names(all_docs) = file_list
names(all_docs) = sub('.txt', '', names(all_docs))
my_corpus = Corpus(VectorSource(all_docs))
names(my_corpus) = file_list
# Preprocessing
my_corpus = tm_map(my_corpus, content_transformer(tolower)) # make everything lowercase
my_corpus = tm_map(my_corpus, content_transformer(removeNumbers)) # remove numbers
my_corpus = tm_map(my_corpus, content_transformer(removePunctuation)) # remove punctuation
my_corpus = tm_map(my_corpus, content_transformer(stripWhitespace)) ## remove excess white-space
my_corpus = tm_map(my_corpus, content_transformer(removeWords), stopwords("SMART"))
DTM = DocumentTermMatrix(my_corpus)
DTM # some basic summary statistics
class(DTM)  # a special kind of sparse matrix format
## You can inspect its entries...
inspect(DTM[1:10,1:20])
DTM = removeSparseTerms(DTM, 0.975)
DTM
# Now a dense matrix
X = as.matrix(DTM)
# Naive Bayes
AP_train = X[1:45,]
AC_train = X[51:95,]
head(author_dirs)
head(labels)
all_docs
names(all_docs)
head(X)
authors = levels(as.factor(labels))
head(authors)
labels = NULL
file_list = NULL
author_train = Sys.glob('./ReutersC50/C50train/*')
author_test = Sys.glob('./ReutersC50/C50tests/*')
author_dirs = c(author_train,author_test)
#author_dirs = author_dirs[1:2]
file_list = NULL
labels = NULL
for(author in author_dirs) {
author_name = substring(author, first=23)
files_to_add = Sys.glob(paste0(author, '/*.txt'))
file_list = append(file_list, files_to_add)
labels = append(labels, rep(author_name, length(files_to_add)))
}
# Need a more clever regex to get better names here
all_docs = lapply(file_list, readerPlain)
names(all_docs) = file_list
names(all_docs) = sub('.txt', '', names(all_docs))
my_corpus = Corpus(VectorSource(all_docs))
names(my_corpus) = file_list
# Preprocessing
my_corpus = tm_map(my_corpus, content_transformer(tolower)) # make everything lowercase
my_corpus = tm_map(my_corpus, content_transformer(removeNumbers)) # remove numbers
my_corpus = tm_map(my_corpus, content_transformer(removePunctuation)) # remove punctuation
my_corpus = tm_map(my_corpus, content_transformer(stripWhitespace)) ## remove excess white-space
my_corpus = tm_map(my_corpus, content_transformer(removeWords), stopwords("SMART"))
DTM = DocumentTermMatrix(my_corpus)
DTM # some basic summary statistics
class(DTM)  # a special kind of sparse matrix format
## You can inspect its entries...
inspect(DTM[1:10,1:20])
DTM = removeSparseTerms(DTM, 0.975)
DTM
# Now a dense matrix
X = as.matrix(DTM)
#Creating a list of Authors
authors = levels(as.factor(labels))
head(authors)
50*50
?colSums
2450/50
w = NULL
w['test']= 4
w
i = 0;
w = NULL
smooth_count = 1/nrow(X)
for (author in authors) {
train = X[i*50+1:i*50+50,]
w[author] = colSums(train + smooth_count)
w[author] = w[author]/sum(w[author])
i = i+1
}
X = as.matrix(DTM)
#Creating a list of Authors
authors = levels(as.factor(labels))
head(authors)
# Naive Bayes
i = 0;
w = NULL
smooth_count = 1/nrow(X)
for (author in authors) {
train = X[i*50+1:i*50+50,]
w[author] = colSums(train + smooth_count)
w[author] = w[author]/sum(w[author])
i = i+1
}
train
X
train = X[1:50,]
train
i = 0;
w = NULL
smooth_count = 1/nrow(X)
for (author in authors) {
train = X[((i*50)+1):((i*50)+50),]
w[author] = colSums(train + smooth_count)
w[author] = w[author]/sum(w[author])
i = i+1
}
train
w
w = matrix()
smooth_count = 1/nrow(X)
for (author in authors) {
train = X[((i*50)+1):((i*50)+50),]
w[author] = colSums(train + smooth_count)
w[author] = w[author]/sum(w[author])
i = i+1
}
w
w = matrix()
View(w)
View(w)
w[2,1] = 5
w = matrix(2500,50)
w = data.frame()
smooth_count = 1/nrow(X)
for (author in authors) {
train = X[((i*50)+1):((i*50)+50),]
w[author] = colSums(train + smooth_count)
w[author] = w[author]/sum(w[author])
i = i+1
}
w = data.frame(authors)
w
smooth_count = 1/nrow(X)
for (author in authors) {
train = X[((i*50)+1):((i*50)+50),]
w[author] = colSums(train + smooth_count)
w[author] = w[author]/sum(w[author])
i = i+1
}
i = 0;
w = NULL
smooth_count = 1/nrow(X)
for (author in authors) {
col = NULL
train = X[((i*50)+1):((i*50)+50),]
col = colSums(train + smooth_count)
names(col) = colnames(train)
temp = w[author]/sum(w[author])
w = cbind(w,temp)
i = i+1
}
w
i = 0;
w = NULL
smooth_count = 1/nrow(X)
for (author in authors) {
col = NULL
train = X[((i*50)+1):((i*50)+50),]
col = colSums(train + smooth_count)
names(col) = colnames(train)
temp = col/sum(col)
w = cbind(w,temp)
i = i+1
}
w
head(w)
colnames(w) = authors
head(w)
fit = matrix(nrow 2500, ncol = 50)
test = X[2501:5000,]
for (i in seq(1:2500)){
for ( j in seq(1:50)){
fit[i,j] = sum(test[i,]*log(w[,j]))
}
}
fit = matrix(nrow = 2500, ncol = 50)
test = X[2501:5000,]
for (i in seq(1:2500)){
for ( j in seq(1:50)){
fit[i,j] = sum(test[i,]*log(w[,j]))
}
}
colnames(fit) = authors
labels_fit = apply(fit,1,which.max)
author_fit = authors[labels_fit]
head(author_fit)
good = 0
for (i in seq(1, 2500)){
if (author_fit[i] == labels[2500+i]){
good = good + 1
}
}
good/2500
train = X[1:2500,]
test = X[2501:5000]
head(train)
?prcomp
pca = prcomp(train)
?predict
test.p = predict(pca,newdata = test)
train = X[1:2500,]
test = X[2501:5000]
pca = prcomp(train)
test.p = predict(pca,newdata = test)
train = X[1:2500,]
test = X[2501:5000,]
pca = prcomp(train)
test.p = predict(pca,newdata = test)
train.pca = pca$x[1:50,]
head(train.pca)
train.pca = pca$x[,1:50]
library(randomForest)
?randomForest
forest = randomForest(train.pca,y = labels[1:2500],ntree = 100)
forest = randomForest(train.pca,y = as.factor(labels[1:2500]),ntree = 100)
predicted = predict(forest,test.p,type = 'response')
labels
predicted = predict(forest,test.p,type = 'response')
good = 0
for (i in seq(1:2500)){
if (predicted[i] == labels[2500+i]) {
good = good + 1
}
}
good/2500
train.pca = pca$x[,1:100]
forest = randomForest(train.pca,y = as.factor(labels[1:2500]),ntree = 200)
predicted = predict(forest,test.p,type = 'response')
good = 0
for (i in seq(1:2500)){
if (predicted[i] == labels[2500+i]) {
good = good + 1
}
}
good/2500
good = 0
for (i in seq(1, 2500)){
if (author_fit[i] == labels[2500+i]){
good = good + 1
}
}
good/2500
dim(X)
setwd("~/Google Drive/UT/Business Analytics/Summer 2015/Predictive Modeling/Scott/HW Repository/STA380HW/HW2")
library(arules)
grocery = read.transactions('../data/groceries.txt', sep = ',', format = 'basket', rm.duplicates = 1)
install.packages('arules')
library(arules)
grocery = read.transactions('../data/groceries.txt', sep = ',', format = 'basket', rm.duplicates = 1)
grocery = read.transactions('./groceries.txt', sep = ',', format = 'basket', rm.duplicates = 1)
class(DTM)  # a special kind of sparse matrix format
library(randomForest)
train = X[1:2500,]
test = X[2501:5000,]
pca = prcomp(train)
test.p = predict(pca,newdata = test)
train.pca = pca$x[,1:100]
forest = randomForest(train.pca,y = as.factor(labels[1:2500]),ntree = 200)
predicted = predict(forest,test.p,type = 'response')
good = 0
for (i in seq(1:2500)){
if (predicted[i] == labels[2500+i]) {
good = good + 1
}
}
good/2500
head(grocery)
groceryrules <- apriori(grocery,parameter=list(support=.01, confidence=.5, maxlen=4))
inspect(groceryrules)
?apriori
